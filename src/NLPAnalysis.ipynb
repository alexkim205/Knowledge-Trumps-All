{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/PatrickApple/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from newspaper import Article\n",
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "from google.cloud import language\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import csv\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data1=pd.read_csv('/Users/PatrickApple/Desktop/PatrickHackathon.csv')\n",
    "#print(data1)\n",
    "#data1=list(data1)\n",
    "#print(data1)\n",
    "\n",
    "with open('/Users/PatrickApple/Documents/GitHub/cdss-hackathon-2018/src/TrumpSiteData.csv', 'r') as f:\n",
    "  reader = csv.reader(f)\n",
    "  data1 = list(reader)\n",
    "\n",
    "#print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unigrams=np.empty([1,len(westwing)],dtype=object)\n",
    "token=''\n",
    "tknzr = TweetTokenizer()\n",
    "type(data1)\n",
    "print(len(data1))\n",
    "\n",
    "frequencies=Counter([])\n",
    "DataNew=pd.DataFrame(columns=['Publisher','Score','Magnitude','Keywords'])\n",
    "\n",
    "for x in range(0,2):#len(data1)):\n",
    "    data1[x] = str(data1[x])\n",
    "    table = str.maketrans({key: None for key in string.punctuation})\n",
    "    data1[x] = data1[x].translate(table)   \n",
    "    token = nltk.word_tokenize(data1[x])\n",
    "    unigrams=list(ngrams(token,1))\n",
    "    y=0\n",
    "    #print(unigrams[x])\n",
    "    for y in range(0,len(unigrams)):\n",
    "\n",
    "        if unigrams[y] not in list(DataNew.columns.values):\n",
    "            DataNew[str(unigrams[y])] = pd.Series(0, index=DataNew.index)\n",
    "            DataNew.set_value(x,str(unigrams[y]),1)\n",
    "        if unigrams[y] in (DataNew.columns.values):\n",
    "            DataNew.set_value(x,str(unigrams[y]),1)\n",
    "            #print(DataNew[y,str(unigrams[y])])\n",
    "        else:\n",
    "        #elif unigrams[y] not in (DataNew.columns.values):\n",
    "            DataNew.set_value(x,str(unigrams[y]),0)\n",
    "    #print(unigrams)\n",
    "    #unigramList[y]=unigramList[y]+unigrams\n",
    "    \n",
    "    #print(Counter(unigrams))\n",
    "    frequencies = frequencies+Counter(unigrams)\n",
    "\n",
    "print(DataNew)\n",
    "#print(frequencies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Counter(unigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(DataNew.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataNew=pd.DataFrame(columns=['Publisher','Score','Magnitude','Keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heres critics president korea fundamental sets change trumps kim stage trump summit missed nuclear meets united north korean \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-37-2ad23107caff>, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-37-2ad23107caff>\"\u001b[0;36m, line \u001b[0;32m26\u001b[0m\n\u001b[0;31m    csvfile = '/Users/PatrickApple/Documents/GitHub/cdss-hackathon-2018/src/Write2F$\u001b[0m\n\u001b[0m                                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "token=''\n",
    "\n",
    "tester = []\n",
    "unigrams = list()\n",
    "for x in range(1,len(data1)):\n",
    "    token = nltk.word_tokenize(data1[x][4])\n",
    "    unigrams += token\n",
    "#print(unigrams)\n",
    "names=list()\n",
    "\n",
    "for x in range(1,len(data1)):\n",
    "    temp = []\n",
    "    token = nltk.word_tokenize(data1[x][4])\n",
    "    for y in unigrams:\n",
    "        tempval = 0\n",
    "        for z in token:\n",
    "            if z == y:\n",
    "                tempval = 1\n",
    "        temp.append(tempval)\n",
    "        if y not in names:\n",
    "            names.append(y)\n",
    "    tester.append(temp)\n",
    "print(tester)\n",
    "print(names)\n",
    "\n",
    "csvfile = '/Users/PatrickApple/Documents/GitHub/cdss-hackathon-2018/src/Write2File.csv\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in tester:\n",
    "        writer.writerow([val])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
